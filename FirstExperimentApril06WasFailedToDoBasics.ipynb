{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a524b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM_for_rainfall_runoff_modelling import CamelsTXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da749cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Homayoun\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Homayoun\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Homayoun\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "from LSTM_for_rainfall_runoff_modelling import CamelsTXT, Model, DataLoader, train_epoch, eval_model, calc_nse\n",
    "\n",
    "def setup_data(basin, sequence_length):\n",
    "    # Training data\n",
    "    start_date_train = pd.to_datetime(\"1980-10-01\", format=\"%Y-%m-%d\")\n",
    "    end_date_train = pd.to_datetime(\"1995-09-30\", format=\"%Y-%m-%d\")\n",
    "    ds_train = CamelsTXT(basin, seq_length=sequence_length, period=\"train\", dates=[start_date_train, end_date_train])\n",
    "    tr_loader = DataLoader(ds_train, batch_size=256, shuffle=True)\n",
    "\n",
    "    # Validation data\n",
    "    means = ds_train.get_means()\n",
    "    stds = ds_train.get_stds()\n",
    "    start_date_val = pd.to_datetime(\"1995-10-01\", format=\"%Y-%m-%d\")\n",
    "    end_date_val = pd.to_datetime(\"2000-09-30\", format=\"%Y-%m-%d\")\n",
    "    ds_val = CamelsTXT(basin, seq_length=sequence_length, period=\"eval\", dates=[start_date_val, end_date_val],\n",
    "                         means=means, stds=stds)\n",
    "    val_loader = DataLoader(ds_val, batch_size=2048, shuffle=False)\n",
    "\n",
    "    # Test data\n",
    "    start_date_test = pd.to_datetime(\"2011-01-01\", format=\"%Y-%m-%d\")\n",
    "    end_date_test = pd.to_datetime(\"2011-01-01\", format=\"%Y-%m-%d\")\n",
    "    ds_test = CamelsTXT(basin, period=\"eval\", dates=[start_date_test, end_date_test],\n",
    "                         means=means, stds=stds)\n",
    "    test_loader = DataLoader(ds_test, batch_size=2048, shuffle=False)\n",
    "\n",
    "    return tr_loader, val_loader, test_loader, ds_val, ds_test\n",
    "\n",
    "def setup_model(hidden_size, dropout_rate, learning_rate):\n",
    "    model = Model(hidden_size=hidden_size, dropout_rate=dropout_rate).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_func = nn.MSELoss()\n",
    "    return model, optimizer, loss_func\n",
    "\n",
    "def train_and_eval_model(model, optimizer, tr_loader, val_loader, n_epochs):\n",
    "    for i in range(n_epochs):\n",
    "        train_epoch(model, optimizer, tr_loader, loss_func, i+1)\n",
    "        obs, preds = eval_model(model, val_loader)\n",
    "        preds = ds_val.local_rescale(preds.numpy(), variable='output')\n",
    "        nse = calc_nse(obs.numpy(), preds)\n",
    "        tqdm.tqdm.write(f\"Validation NSE: {nse:.2f}\")\n",
    "\n",
    "def evaluate_and_plot_results(model, test_loader, ds_val, ds_test):\n",
    "    start_date_test = pd.to_datetime(\"2000-01-01\", format=\"%Y-%m-%d\")\n",
    "    end_date_test = pd.to_datetime(\"2011-01-30\", format=\"%Y-%m-%d\")\n",
    "    obs, preds = eval_model(model, test_loader)\n",
    "    preds = ds_val.local_rescale(preds.numpy(), variable='output')\n",
    "    obs = obs.numpy()\n",
    "    nse = calc_nse(obs, preds)\n",
    "    # Plot results\n",
    "    start_date = end_date_test\n",
    "    end_date = end_date_test + pd.DateOffset(days=1)\n",
    "    date_range = pd.date_range(start_date, end_date, freq='D').date\n",
    "    print(obs.shape)\n",
    "    print(preds.shape)\n",
    "    # Aggregate the observed and predicted discharge values for each day\n",
    "    obs_daily_mean = obs.mean(axis=1)\n",
    "    preds_daily_mean = preds.mean(axis=1)\n",
    "    \n",
    "    # Plot results\n",
    "    print(date_range)\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.plot(date_range, obs_daily_mean, label=\"observation\")\n",
    "    ax.plot(date_range, preds_daily_mean, label=\"prediction\")\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Basin {basin} - Test set NSE: {nse:.3f}\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Discharge (mm/d)\")\n",
    "    ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))  # Set the x-axis tick locator to use integer values\n",
    "    ax.xaxis.set_tick_params(rotation=90)  # Rotate x-axis labels for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7e8c9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No forcing file file found for Basin 01022500",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2372\\608400532.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mDEVICE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtr_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetup_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetup_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2372\\4116386558.py\u001b[0m in \u001b[0;36msetup_data\u001b[1;34m(basin, sequence_length)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mstart_date_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1980-10-01\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%Y-%m-%d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mend_date_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1995-09-30\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%Y-%m-%d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mds_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCamelsTXT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_date_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mtr_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\neuralhydrology\\DeepLearningProject\\TaimoorProject\\LSTM_for_rainfall_runoff_modelling.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, basin, seq_length, period, dates, means, stds)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;31m# load data into memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;31m# store number of samples as class attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\neuralhydrology\\DeepLearningProject\\TaimoorProject\\LSTM_for_rainfall_runoff_modelling.py\u001b[0m in \u001b[0;36m_load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;34m\"\"\"Load input and output data from text files.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_forcing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'QObs(mm/d)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_discharge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marea\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\neuralhydrology\\DeepLearningProject\\TaimoorProject\\LSTM_for_rainfall_runoff_modelling.py\u001b[0m in \u001b[0;36mload_forcing\u001b[1;34m(basin)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbasin\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'No forcing file file found for Basin {basin}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No forcing file file found for Basin 01022500"
     ]
    }
   ],
   "source": [
    "    basin = '01022500'\n",
    "    hidden_size = 10\n",
    "    dropout_rate = 0.0\n",
    "    learning_rate = 1e-3\n",
    "    sequence_length = 365\n",
    "\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    tr_loader, val_loader, test_loader, ds_val, ds_test = setup_data(basin, sequence_length)\n",
    "    model, optimizer, loss_func = setup_model(hidden_size, dropout_rate, learning_rate)\n",
    "\n",
    "    n_epochs = 1\n",
    "    train_and_eval_model(model, optimizer, tr_loader, val_loader, n_epochs)\n",
    "    evaluate_and_plot_results(model, test_loader, ds_val, ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f83b111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cffbd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4bbb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28ae51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
